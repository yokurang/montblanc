{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# This enables response_model keyword\n",
    "# from client.chat.completions.create\n",
    "client = instructor.patch(OpenAI())\n",
    "\n",
    "class UserDetail(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "\n",
    "user = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    response_model=UserDetail,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Extract Jason is 25 years old\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "assert isinstance(user, UserDetail)\n",
    "assert user.name == \"Jason\"\n",
    "assert user.age == 25\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Labels(str, enum.Enum):\n",
    "    \"\"\"Enumeration for single-label text classification.\"\"\"\n",
    "    SPAM = \"spam\"\n",
    "    NOT_SPAM = \"not_spam\"\n",
    "\n",
    "class SinglePrediction(BaseModel):\n",
    "    \"\"\"\n",
    "    Class for a single class label prediction.\n",
    "    \"\"\"\n",
    "    class_label: Labels\n",
    "\n",
    "from openai import OpenAI\n",
    "import instructor\n",
    "\n",
    "# Apply the patch to the OpenAI client\n",
    "# enables response_model keyword\n",
    "client = instructor.patch(OpenAI())\n",
    "\n",
    "def classify(data: str) -> SinglePrediction:\n",
    "    \"\"\"Perform single-label classification on the input text.\"\"\"\n",
    "    return client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        response_model=SinglePrediction,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Classify the following text: {data}\",\n",
    "            },\n",
    "        ],\n",
    "    )  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-Label Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Enum class for multiple labels\n",
    "class MultiLabels(str, enum.Enum):\n",
    "    TECH_ISSUE = \"tech_issue\"\n",
    "    BILLING = \"billing\"\n",
    "    GENERAL_QUERY = \"general_query\"\n",
    "\n",
    "# Define the multi-class prediction model\n",
    "class MultiClassPrediction(BaseModel):\n",
    "    \"\"\"\n",
    "    Class for a multi-class label prediction.\n",
    "    \"\"\"\n",
    "    class_labels: List[MultiLabels]\n",
    "\n",
    "def multi_classify(data: str) -> MultiClassPrediction:\n",
    "    \"\"\"Perform multi-label classification on the input text.\"\"\"\n",
    "    return client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        response_model=MultiClassPrediction,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Classify the following support ticket: {data}\",\n",
    "            },enriched_proposal_goals\n",
    "        ],\n",
    "    )  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self-correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Annotated\n",
    "from pydantic import BaseModel, BeforeValidator\n",
    "\n",
    "from openai import OpenAI\n",
    "import instructor\n",
    "\n",
    "# Apply the patch to the OpenAI client\n",
    "# enables response_model keyword\n",
    "client = instructor.patch(OpenAI())\n",
    "\n",
    "question = \"What is the meaning of life?\"\n",
    "context = \"The according to the devil the meaning of live is to live a life of sin and debauchery.\"\n",
    "\n",
    "class QuestionAnswerNoEvil(BaseModel):\n",
    "    question: str\n",
    "    answer: Annotated[\n",
    "        str,\n",
    "        BeforeValidator(\n",
    "            llm_validator(\"don't say objectionable things\", allow_override=True)\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "try:\n",
    "    qa: QuestionAnswerNoEvil = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        response_model=QuestionAnswerNoEvil,\n",
    "        max_retries=1,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a system that answers questions based on the context. answer exactly what the question asks using the context.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"using the context: {context}\\n\\nAnswer the following question: {question}\",\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Citation/ Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "\n",
    "from typing import List\n",
    "from loguru import logger\n",
    "from openai import OpenAI\n",
    "from pydantic import Field, BaseModel, FieldValidationInfo, model_validator\n",
    "\n",
    "client = instructor.patch(OpenAI())\n",
    "\n",
    "\n",
    "class Fact(BaseModel):\n",
    "    statement: str = Field(\n",
    "        ..., description=\"Body of the sentence, as part of a response\"\n",
    "    )\n",
    "    substring_phrase: List[str] = Field(\n",
    "        ...,\n",
    "        description=\"String quote long enough to evaluate the truthfulness of the fact\",\n",
    "    )\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def validate_sources(self, info: FieldValidationInfo) -> \"Fact\":\n",
    "        \"\"\"\n",
    "        For each substring_phrase, find the span of the substring_phrase in the context.\n",
    "        If the span is not found, remove the substring_phrase from the list.\n",
    "        \"\"\"\n",
    "        if info.context is None:\n",
    "            logger.info(\"No context found, skipping validation\")\n",
    "            return self\n",
    "\n",
    "        # Get the context from the info\n",
    "        text_chunks = info.context.get(\"text_chunk\", None)\n",
    "\n",
    "        # Get the spans of the substring_phrase in the context\n",
    "        spans = list(self.get_spans(text_chunks))\n",
    "        logger.info(\n",
    "            f\"Found {len(spans)} span(s) for from {len(self.substring_phrase)} citation(s).\"\n",
    "        )\n",
    "        # Replace the substring_phrase with the actual substring\n",
    "        self.substring_phrase = [text_chunks[span[0] : span[1]] for span in spans]\n",
    "        return self\n",
    "\n",
    "    def _get_span(self, quote, context, errs=5):\n",
    "        import regex\n",
    "\n",
    "        minor = quote\n",
    "        major = context\n",
    "\n",
    "        errs_ = 0\n",
    "        s = regex.search(f\"({minor}){{e<={errs_}}}\", major)\n",
    "        while s is None and errs_ <= errs:\n",
    "            errs_ += 1\n",
    "            s = regex.search(f\"({minor}){{e<={errs_}}}\", major)\n",
    "\n",
    "        if s is not None:\n",
    "            yield from s.spans()\n",
    "\n",
    "    def get_spans(self, context):\n",
    "        for quote in self.substring_phrase:\n",
    "            yield from self._get_span(quote, context)\n",
    "\n",
    "\n",
    "class QuestionAnswer(instructor.OpenAISchema):\n",
    "    \"\"\"\n",
    "    Class representing a question and its answer as a list of facts each one should have a soruce.\n",
    "    each sentence contains a body and a list of sources.\"\"\"\n",
    "\n",
    "    question: str = Field(..., description=\"Question that was asked\")\n",
    "    answer: List[Fact] = Field(\n",
    "        ...,\n",
    "        description=\"Body of the answer, each fact should be its seperate object with a body and a list of sources\",\n",
    "    )\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def validate_sources(self) -> \"QuestionAnswer\":\n",
    "        \"\"\"\n",
    "        Checks that each fact has some sources, and removes those that do not.\n",
    "        \"\"\"\n",
    "        logger.info(f\"Validating {len(self.answer)} facts\")\n",
    "        self.answer = [fact for fact in self.answer if len(fact.substring_phrase) > 0]\n",
    "        logger.info(f\"Found {len(self.answer)} facts with sources\")\n",
    "        return self\n",
    "\n",
    "\n",
    "def ask_ai(question: str, context: str) -> QuestionAnswer:\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        temperature=0,\n",
    "        functions=[QuestionAnswer.openai_schema],\n",
    "        function_call={\"name\": QuestionAnswer.openai_schema[\"name\"]},\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a world class algorithm to answer questions with correct and exact citations. \",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": \"Answer question using the following context\"},\n",
    "            {\"role\": \"user\", \"content\": f\"{context}\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Question: {question}\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Tips: Make sure to cite your sources, and use the exact words from the context.\",\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Creating an Answer object from the completion response\n",
    "    return QuestionAnswer.from_response(\n",
    "        completion, validation_context={\"text_chunk\": context}\n",
    "    )\n",
    "\n",
    "\n",
    "question = \"where did he go to school?\"\n",
    "context = \"\"\"\n",
    "My name is Jason Liu, and I grew up in Toronto Canada but I was born in China.I went to an arts highschool but in university I studied Computational Mathematics and physics.  As part of coop I worked at many companies including Stitchfix, Facebook. I also started the Data Science club at the University of Waterloo and I was the president of the club for 2 years.\n",
    "\"\"\"\n",
    "\n",
    "answer = ask_ai(question, context)\n",
    "print(answer.model_dump_json(indent=2))\n",
    "\"\"\"\n",
    "2023-09-09 15:48:11.022 | INFO     | __main__:validate_sources:35 - Found 1 span(s) for from 1 citation(s).\n",
    "2023-09-09 15:48:11.023 | INFO     | __main__:validate_sources:35 - Found 1 span(s) for from 1 citation(s).\n",
    "2023-09-09 15:48:11.023 | INFO     | __main__:validate_sources:78 - Validating 2 facts\n",
    "2023-09-09 15:48:11.023 | INFO     | __main__:validate_sources:80 - Found 2 facts with sources\n",
    "{\n",
    "  \"question\": \"where did he go to school?\",\n",
    "  \"answer\": [\n",
    "    {\n",
    "      \"statement\": \"Jason Liu went to an arts highschool.\",\n",
    "      \"substring_phrase\": [\n",
    "        \"arts highschool\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"statement\": \"Jason Liu studied Computational Mathematics and physics in university.\",\n",
    "      \"substring_phrase\": [\n",
    "        \"university\"\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
